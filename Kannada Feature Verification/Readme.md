# Kannada Emotional Speech Dataset (Subset)

## ðŸ“Œ Overview
The **Kannada Emotional Speech Dataset** is a publicly available dataset designed for **speech emotion recognition (SER)** in the **Kannada language**. The original dataset, hosted on Zenodo ([link](https://zenodo.org/records/6345107)), consists of **468 audio samples** recorded by **13 speakers** (4 male, 9 female) across **six emotions**:

1. **Anger**
2. **Sadness**
3. **Surprise**
4. **Happiness**
5. **Fear**
6. **Neutral**

Each speaker pronounced **six different sentences**, and the dataset follows a structured **naming convention** (e.g., `AA-EE-SS.wav`), where:
- `AA` represents the **speaker ID** (01-13).
- `EE` represents the **emotion ID** (01-06).
- `SS` represents the **sentence ID** (01-06).

The dataset was **collected from volunteers** and is freely available under a **Creative Commons license**. However, since the recordings were made in an **uncontrolled environment**, they may include background noise or variations in speech clarity.

## ðŸ“Œ Subset Used in This Project
For this project, we selected a **balanced subset of 100 samples** from the original dataset with an approximate distribution of:
- **Anger** â†’ 16 samples
- **Sadness** â†’ 16 samples
- **Surprise** â†’ 17 samples
- **Happiness** â†’ 17 samples
- **Fear** â†’ 17 samples
- **Neutral** â†’ 17 samples

## ðŸ“Œ Feature Extraction
We extracted key **acoustic features** from the audio files:
- **MFCCs** (Mel-Frequency Cepstral Coefficients) â€“ 40 coefficients
- **Mel Spectrogram** values â€“ 128 coefficients
- **ZCR** (Zero Crossing Rate)
- **RMSE** (Root Mean Square Energy)

## ðŸ“Œ Preprocessing
Before feeding the extracted features into the model:
- **Standardization**: We applied `StandardScaler()` to normalize the features.
- **Label Encoding**: Emotions were mapped to numeric values:
  - **Anger â†’ 0**
  - **Sadness â†’ 1**
  - **Surprise â†’ 2**
  - **Happiness â†’ 3**
  - **Fear â†’ 4**
  - **Neutral â†’ 5**

## ðŸ“Œ Model Used
We trained a **CNN** model for **emotion classification**, leveraging the extracted features to improve prediction accuracy.

## ðŸ“Œ Acknowledgments
This dataset is credited to the original contributors on Zenodo. The subset used here is for **research and educational purposes** in the field of speech emotion recognition.
